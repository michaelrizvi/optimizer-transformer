experiment:
  num_runs: 1
  device: cuda
  seed: 43
  save_model: true

wandb:
  enabled: false
  project: length-generalization
  entity: null
  offline: false
  log_during_training: false
  log_final: true

dataset:
  # Dataset type
  name: ShuffleDyckDataset

  # Training data - shorter sequences (1-16)
  train_min_range: 1
  train_max_range: 10

  # Test/validation data - longer sequences (17-32)
  test_min_range: 11
  test_max_range: 20

  # Dataset sizes
  train_samples: 500
  val_samples: 200
  test_samples: 200

  # Vocabulary parameters (ShuffleDyckDataset has fixed vocab: 0='(', 1=')', 2='0', 3='1', sep, pad)
  vocab_size: 8  # Large enough to accommodate all tokens
  sep_token: 7 
  pad_token: 6 
  max_length: 128

model:
  d_model: 32 
  n_layers: 1
  n_heads: 8 
  d_ff: 64 
  max_len: 64
  dropout: 0.1
  model_count: 1
  init: regular
  position_encoding_type: none  # Use RoPE for position encoding
  rope_base: 500000  # Large base for better long-range generalization

optimizer:
  name: SGD

  # SGD parameters
  lr: 0.001
  momentum: 0.9
  batch_size: 16 

  # Training parameters
  epochs: 1000
  es_acc: 0.999

  # Evaluation parameters
  eval_frequency: 10
