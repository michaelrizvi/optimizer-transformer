experiment:
  num_runs: 5
  device: cuda
  seed: 42

wandb:
  enabled: true 
  project: length-generalization
  entity: null
  offline: false
  log_during_training: true
  log_final_only: false

dataset:
  # Training data - shorter sequences (1-10)
  train_min_range: 1
  train_max_range: 10
  
  # Test/validation data - longer sequences (11-15) 
  test_min_range: 11
  test_max_range: 15
  
  # Dataset sizes
  train_samples: 2000
  val_samples: 500
  test_samples: 500
  
  # Vocabulary parameters
  vocab_size: 110
  sep_token: 102
  pad_token: 103
  max_length: 32

model:
  d_model: 32
  n_layers: 2
  n_heads: 4
  d_ff: 128
  max_len: 64
  dropout: 0.1
  model_count: 1
  init: regular

optimizer:
  name: SGD
  
  # SGD parameters
  lr: 0.001
  momentum: 0.9
  batch_size: 128
  
  # Training parameters
  epochs: 400
  es_acc: 0.99
  
  # Position offset parameters (disabled by default)
  use_position_offsets: false
  max_position_offset: 16
  
  # Evaluation parameters
  eval_frequency: 10